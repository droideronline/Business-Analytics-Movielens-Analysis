{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "link:https://grouplens.org/datasets/movielens/1m/\n"
      ],
      "metadata": {
        "id": "3FDCXVAE6ZNw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yjcJWVtonEz"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQo3ZoW1onE6"
      },
      "source": [
        "## Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqDuea_2onE_"
      },
      "outputs": [],
      "source": [
        "# Import Movies Dataset\n",
        "# Import Movies Dataset\n",
        "dfMovies = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/movies.dat',sep=\"::\",names=[\"MovieID\",\"Title\",\"Genres\"],engine='python',encoding='ISO-8859-1')\n",
        "dfMovies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNqDB_5OonFF"
      },
      "outputs": [],
      "source": [
        "# Import Ratings Dataset\n",
        "dfRatings = pd.read_csv(\"https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/ratings.dat\",sep=\"::\",names=[\"UserID\",\"MovieID\",\"Rating\",\"Timestamp\"],engine='python')\n",
        "dfRatings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DEVazlGonFI"
      },
      "outputs": [],
      "source": [
        "# Import Ratings Dataset\n",
        "dfUsers = pd.read_csv(\"https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/users.dat\",sep=\"::\",names=[\"UserID\",\"Gender\",\"Age\",\"Occupation\",\"Zip-code\"],engine='python')\n",
        "dfUsers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU1olGKUonFK"
      },
      "outputs": [],
      "source": [
        "dfMovies.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbScPYmlonFL"
      },
      "outputs": [],
      "source": [
        "dfUsers.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVIphxVQonFN"
      },
      "outputs": [],
      "source": [
        "dfRatings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfeNTOyjonFO"
      },
      "source": [
        "## Create a new dataset [Master_Data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWhJkMVhonFP"
      },
      "outputs": [],
      "source": [
        "dfMovieRatings = pd.merge(pd.merge(dfRatings,dfMovies),dfUsers)\n",
        "dfMovieRatings.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG_Fdw4monFR"
      },
      "outputs": [],
      "source": [
        "# to check whether merging does not changes any dataset\n",
        "dfMovieRatings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVWfFmBhonFT"
      },
      "outputs": [],
      "source": [
        "dfMaster =pd.merge(pd.merge(dfRatings, dfMovies), dfUsers)\n",
        "dfMaster.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFvMA4cwonFW"
      },
      "outputs": [],
      "source": [
        "dfMaster.to_csv(\"Master.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS5d6qVPonFX"
      },
      "source": [
        "## Explore the datasets using visual representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznZMNUOonFZ"
      },
      "source": [
        "### User Age Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbQBItUMonFa"
      },
      "outputs": [],
      "source": [
        "# Users with Different Age Groups\n",
        "dfMaster['Age'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T8w-N0aonFc"
      },
      "outputs": [],
      "source": [
        "# Plot for users with different age groups\n",
        "dfMaster['Age'].value_counts().plot(kind='bar')\n",
        "plt.xlabel(\"Age\")\n",
        "plt.title(\"User Age Distribution\")\n",
        "plt.ylabel('Users Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh2xj864onFd"
      },
      "source": [
        "### User rating of the movie “Toy Story”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r00MhydaonFf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Toy Story\n",
        "toystoryRating = dfMaster[dfMaster['Title'].str.contains('Toy Story') == True]\n",
        "toystoryRating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4llyyElonFh"
      },
      "outputs": [],
      "source": [
        "toystoryRating.groupby([\"Title\",\"Rating\"]).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HEc9Eb6onFi"
      },
      "outputs": [],
      "source": [
        "toystoryRating.groupby([\"Title\",\"Rating\"]).size().unstack().plot(kind='barh',stacked=False,legend=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ1XI1lKonFk"
      },
      "source": [
        "### Top 25 movies by viewership rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpjLlzBEonFl"
      },
      "outputs": [],
      "source": [
        "dfTop25 = dfMaster.groupby('Title').size().sort_values(ascending=False)[:25]\n",
        "dfTop25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRXGu6QmonFm"
      },
      "outputs": [],
      "source": [
        "dfTop25.plot(kind='barh',alpha=0.6,figsize=(7,7))\n",
        "plt.xlabel(\"Viewership Ratings Count\")\n",
        "plt.ylabel(\"Movies (Top 25)\")\n",
        "plt.title(\"Top 25 movies by viewership rating\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzl2awCyonFp"
      },
      "outputs": [],
      "source": [
        "# Dropping rows with missing values\n",
        "dfMaster.dropna(axis=0, inplace=True)\n",
        "\n",
        "# Dropping columns with missing values\n",
        "dfMaster.dropna(axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p29lwntnonFq"
      },
      "source": [
        "### Find the ratings for all the movies reviewed by for a particular user of user id = 2696"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmAOk7f2onFr"
      },
      "outputs": [],
      "source": [
        "userId = 2696\n",
        "userRatingById = dfMaster[dfMaster[\"UserID\"] == userId]\n",
        "userRatingById"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOnqecKruT_n"
      },
      "source": [
        "Bokeh visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcfPfydQv5kj"
      },
      "outputs": [],
      "source": [
        "!pip install bokeh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScC6TEuP4zTV"
      },
      "outputs": [],
      "source": [
        "dfGenres = pd.read_csv(\"https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/Geners.dat\",sep=\"::\",names=[\"GenreID\",\"Genre\"],engine='python')\n",
        "dfGenres.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8rCt-6X5zSc"
      },
      "outputs": [],
      "source": [
        "dfGenres.to_csv(\"Genres.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwpbRJnGxuEh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bokeh.layouts import row, column\n",
        "from bokeh.models import ColumnDataSource, Div\n",
        "from bokeh.plotting import figure, curdoc\n",
        "from bokeh.transform import factor_cmap\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.palettes import Spectral4\n",
        "\n",
        "# read the master dataset\n",
        "df = pd.read_csv('Master.csv')\n",
        "df1=pd.read_csv('Genres.csv')\n",
        "\n",
        "# create data sources for the plots\n",
        "movies_source = ColumnDataSource(data=dict(movie_id=df['MovieID'], title=df['Title'], genres=df1['Genre']))\n",
        "users_source = ColumnDataSource(data=dict(user_id=df['UserID'], gender=df['Gender'], age=df['Age'], occupation=df['Occupation']))\n",
        "ratings_source = ColumnDataSource(data=dict(movie_id=df['MovieID'], rating=df['Rating']))\n",
        "\n",
        "# create a scatter plot for movies by genre\n",
        "genres = sorted(df['Genres'].unique())\n",
        "colors = factor_cmap('Genres', palette=Spectral4, factors=genres)\n",
        "movies_plot = figure(title='Movies by Genre', x_axis_label='MovieID', y_axis_label='Genres', tools='pan,box_select')\n",
        "movies_plot.scatter('MovieID', 'Genres', source=movies_source, color=colors)\n",
        "\n",
        "# create a histogram for user ages\n",
        "age_hist, age_edges = np.histogram(df['Age'], bins=20)\n",
        "age_plot = figure(title='User Age Distribution', x_axis_label='Age', y_axis_label='Count', tools='pan,box_select')\n",
        "age_plot.quad(top=age_hist, bottom=0, left=age_edges[:-1], right=age_edges[1:], line_color='white')\n",
        "\n",
        "# create a bar chart for movie ratings\n",
        "rating_counts = df['Rating'].value_counts().sort_index()\n",
        "rating_plot = figure(title='Movie Ratings Distribution', x_axis_label='Rating', y_axis_label='Count', tools='pan,box_select')\n",
        "rating_plot.vbar(x=rating_counts.index.astype(str), top=rating_counts.values, width=0.9)\n",
        "\n",
        "# create a summary div to display some stats about the dataset\n",
        "summary_div = Div(text=f\"<h2>Movie Recommendation System</h2>\"\n",
        "                       f\"<p><b>Number of movies:</b> {len(df['MovieID'].unique())}</p>\"\n",
        "                       f\"<p><b>Number of users:</b> {len(df['UserID'].unique())}</p>\"\n",
        "                       f\"<p><b>Number of ratings:</b> {len(df)}</p>\"\n",
        "                       f\"<p><b>Average rating:</b> {df['Rating'].mean():.2f}</p>\")\n",
        "\n",
        "# display the plots and summary div in the notebook\n",
        "output_notebook()\n",
        "show(column(summary_div, row(movies_plot, age_plot, rating_plot)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IDjN5e_onFt"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-xpa8kSonFt"
      },
      "source": [
        "### Find out all the unique genres "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5j4E1NzonFu"
      },
      "outputs": [],
      "source": [
        "#dfGenres = dfMaster[]\n",
        "dfGenres = dfMaster['Genres'].str.split(\"|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7BHsZUConFv"
      },
      "outputs": [],
      "source": [
        "dfGenres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYdW1eOzonFw"
      },
      "outputs": [],
      "source": [
        "\n",
        "listGenres = set()\n",
        "for genre in dfGenres:\n",
        "    listGenres = listGenres.union(set(genre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6dbl--donFx"
      },
      "outputs": [],
      "source": [
        "# All Unique genres\n",
        "listGenres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_D2O4tZonFx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwh-gfrFonFy"
      },
      "source": [
        "### Create a separate column for each genre category with a one-hot encoding ( 1 and 0) whether or not the movie belongs to that genre. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAj3CiiUonF0"
      },
      "outputs": [],
      "source": [
        "ratingsOneHot = dfMaster['Genres'].str.get_dummies(\"|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkwzNr9conF1"
      },
      "outputs": [],
      "source": [
        "ratingsOneHot.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfiUjzSbonF3"
      },
      "outputs": [],
      "source": [
        "dfMaster = pd.concat([dfMaster,ratingsOneHot],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsWdrmRKonF4"
      },
      "outputs": [],
      "source": [
        "dfMaster.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyiqnm9qonF6"
      },
      "outputs": [],
      "source": [
        "dfMaster.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15-xBG3qonF7"
      },
      "outputs": [],
      "source": [
        "dfMaster.to_csv(\"Final_Master.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt5mTQFDonF8"
      },
      "source": [
        "### Determine the features affecting the ratings of any particular movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4d9j8YTonF9"
      },
      "outputs": [],
      "source": [
        "dfMaster[[\"title\",\"Year\"]] = dfMaster.Title.str.extract(\"(.)\\s\\((.\\d+)\",expand=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbemlYp_onF-"
      },
      "outputs": [],
      "source": [
        "dfMaster = dfMaster.drop(columns=[\"title\"])\n",
        "dfMaster.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5gOnoqYonF_"
      },
      "outputs": [],
      "source": [
        "dfMaster.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQb09AX1onGB"
      },
      "outputs": [],
      "source": [
        "dfMaster['Year'] = dfMaster.Year.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGhNPy1XonGC"
      },
      "outputs": [],
      "source": [
        "dfMaster['Movie_Age'] = 2000 - dfMaster.Year\n",
        "dfMaster.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPOVGlyOonGD"
      },
      "outputs": [],
      "source": [
        "dfMaster['Gender'] = dfMaster.Gender.str.replace('F','1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ72LGyGonGF"
      },
      "outputs": [],
      "source": [
        "dfMaster['Gender'] = dfMaster.Gender.str.replace('M','0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nhj8F_bonGF"
      },
      "outputs": [],
      "source": [
        "dfMaster['Gender'] = dfMaster.Gender.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1dYnXLMonGG"
      },
      "outputs": [],
      "source": [
        "dfMaster.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMAQiX8donGH"
      },
      "outputs": [],
      "source": [
        "dfGenderAffecting = dfMaster.groupby('Gender').size().sort_values(ascending=False)[:25]\n",
        "dfGenderAffecting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLFEOmYYonGI"
      },
      "outputs": [],
      "source": [
        "dfMaster.groupby([\"Gender\",\"Rating\"]).size().unstack().plot(kind='bar',stacked=False,legend=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bmzDjTnonGJ"
      },
      "outputs": [],
      "source": [
        "dfMaster.groupby([\"Age\",\"Rating\"]).size().unstack().plot(kind='bar',stacked=False,legend=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K3-QHhDonGK"
      },
      "outputs": [],
      "source": [
        "dfMaster.groupby([\"Occupation\",\"Rating\"]).size().unstack().plot(kind='bar',stacked=False,legend=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bddn61oOonGL"
      },
      "outputs": [],
      "source": [
        "dfMaster.groupby([\"Year\",\"Rating\"]).size().unstack().plot(kind='bar',stacked=False,legend=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53GkfkHkonGM"
      },
      "outputs": [],
      "source": [
        "dfMaster.groupby([\"Movie_Age\",\"Rating\"]).size().unstack().plot(kind='bar',stacked=False,legend=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBZFTBjAHc5T"
      },
      "source": [
        "# Dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI8aEmZgHcmY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMJsqIK3TCZt"
      },
      "outputs": [],
      "source": [
        "dfMaster = dfMaster.rename(columns={\"Children's\": 'Children'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2adJ3Wj5HnDw"
      },
      "outputs": [],
      "source": [
        "# Define the features and labels\n",
        "features = dfMaster[['MovieID', 'Age', 'Occupation']].values\n",
        "labels = dfMaster['Rating'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xva--sy3H1W9"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bfqt1y9H0yf"
      },
      "outputs": [],
      "source": [
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=3)\n",
        "pca_features = pca.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSaebKbJVVWs"
      },
      "outputs": [],
      "source": [
        "labels_pca = pca_features[-1 :]\n",
        "labels_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu5jf90eQ9vG"
      },
      "outputs": [],
      "source": [
        "pca_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkrAz_OnH9ER"
      },
      "outputs": [],
      "source": [
        "# Plot the PCA-reduced features\n",
        "plt.scatter(pca_features[:, 0], pca_features[:, 1], c=labels, cmap='viridis')\n",
        "plt.title('PCA Dimensionality Reduction')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYlxMiaKH_6j"
      },
      "source": [
        "## SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtazSbdKIFLK"
      },
      "outputs": [],
      "source": [
        "# Apply SVD for dimensionality reduction\n",
        "svd = TruncatedSVD(n_components=3)\n",
        "svd_features = svd.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqDHOJsjIKwA"
      },
      "outputs": [],
      "source": [
        "# Plot the SVD-reduced features\n",
        "plt.scatter(svd_features[:, 0], svd_features[:, 1], c=labels, cmap='viridis')\n",
        "plt.title('SVD Dimensionality Reduction')\n",
        "plt.xlabel('SV1')\n",
        "plt.ylabel('SV2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering**"
      ],
      "metadata": {
        "id": "lDXpzzSo6S6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a random subset of the ratings dataset\n",
        "ratings = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/ratings.dat', sep='::', names=['user_id', 'movie_id', 'rating', 'timestamp'], engine='python')\n",
        "ratings = ratings.sample(n=100000, random_state=42)\n",
        "\n",
        "# Load the movies dataset\n",
        "movies = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/movies.dat', sep='::', names=['movie_id', 'title', 'genres'], engine='python', encoding='ISO-8859-1')\n",
        "\n",
        "# Merge the movies and ratings datasets\n",
        "df = pd.merge(movies, ratings, on='movie_id')\n",
        "\n",
        "# Convert the dataset into a pivot table with users as rows and movies as columns\n",
        "pivot_table = pd.pivot_table(df, index='user_id', columns='title', values='rating', fill_value=0)\n",
        "\n",
        "# Scale the pivot table\n",
        "scaler = MinMaxScaler()\n",
        "pivot_table_scaled = scaler.fit_transform(pivot_table)\n",
        "\n",
        "# Compute the KNN graph\n",
        "n_neighbors = 10\n",
        "knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
        "knn.fit(pivot_table_scaled)\n",
        "knn_graph = knn.kneighbors_graph(pivot_table_scaled)\n",
        "\n",
        "# Compute the DBSCAN clusters\n",
        "eps = 0.5\n",
        "min_samples = 5\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
        "dbscan.fit(knn_graph)\n",
        "\n",
        "# Compute the KMeans clusters\n",
        "n_clusters = 5\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(pivot_table_scaled)\n",
        "\n",
        "# Plot the results\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot the KNN graph\n",
        "axs[0].imshow(knn_graph.toarray())\n",
        "axs[0].set_title(f'KNN Graph (k={n_neighbors})')\n",
        "\n",
        "# Plot the DBSCAN clusters\n",
        "unique_labels = np.unique(dbscan.labels_)\n",
        "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
        "for label, color in zip(unique_labels, colors):\n",
        "    if label == -1:\n",
        "        color = 'gray'\n",
        "    class_member_mask = (dbscan.labels_ == label)\n",
        "    xy = pivot_table_scaled[class_member_mask]\n",
        "    axs[1].scatter(xy[:, 0], xy[:, 1], c=color, label=f'Cluster {label}')\n",
        "axs[1].set_title(f'DBSCAN Clustering (eps={eps}, min_samples={min_samples})')\n",
        "axs[1].legend()\n",
        "\n",
        "# Plot the KMeans clusters\n",
        "unique_labels = np.unique(kmeans.labels_)\n",
        "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
        "for label, color in zip(unique_labels, colors):\n",
        "    class_member_mask = (kmeans.labels_ == label)\n",
        "    xy = pivot_table_scaled[class_member_mask]\n",
        "    axs[2].scatter(xy[:, 0], xy[:, 1], c=color, label=f'Cluster {label}')\n",
        "axs[2].set_title(f'KMeans Clustering (n_clusters={n_clusters})')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "npdV3jUY6hdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP_0GlAkonGN"
      },
      "source": [
        "# Develop an appropriate model to predict the movie ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veWkuQHBonGO"
      },
      "outputs": [],
      "source": [
        "#First 500 extracted records\n",
        "first_500 = dfMaster[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_M65-OnonGO"
      },
      "outputs": [],
      "source": [
        "first_500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loZErO_8onGP"
      },
      "outputs": [],
      "source": [
        "#Use the following features:movie id,age,occupation\n",
        "features = first_500[['MovieID','Age','Occupation']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0LeFai8onGQ"
      },
      "outputs": [],
      "source": [
        "#Use rating as label\n",
        "labels = first_500[['Rating']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U42JN3pOonGV"
      },
      "outputs": [],
      "source": [
        "#Create train and test data set\n",
        "train, test, train_labels, test_labels = train_test_split(features,labels,test_size=0.33,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYNTNnb-xh5w"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejcATgrPxbFy"
      },
      "outputs": [],
      "source": [
        "# Stochastic Gradient Descent\n",
        "\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(train, train_labels)\n",
        "Y_pred = sgd.predict(test)\n",
        "acc_sgd = round(sgd.score(train, train_labels) * 100, 2)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji6iRXdOxvyU"
      },
      "outputs": [],
      "source": [
        "# Linear SVC\n",
        "\n",
        "linear_svc = LinearSVC()\n",
        "linear_svc.fit(train, train_labels)\n",
        "Y_pred = linear_svc.predict(test)\n",
        "acc_linear_svc = round(linear_svc.score(train, train_labels) * 100, 2)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1i1dZfNx2tP"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machines\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(train, train_labels)\n",
        "Y_pred = svc.predict(test)\n",
        "acc_svc = round(svc.score(train, train_labels) * 100, 2)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Soj6bepuycXv"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Support Vector Machines','Linear SVC','Stochastic Gradient Descent'],\n",
        "    'Score': [acc_svc,acc_linear_svc,acc_sgd]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjxZLwHhwi6k"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_n90ECsonGs"
      },
      "outputs": [],
      "source": [
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(train, train_labels)\n",
        "Y_pred = knn.predict(test)\n",
        "acc_knn = round(knn.score(train, train_labels) * 100, 2)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deUkdwFGzmFo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm_knn = confusion_matrix(test_labels, Y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_knn = classification_report(test_labels, Y_pred)\n",
        "print(report_knn)\n",
        "cm_knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDU-aZrXonG9"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(train, train_labels)\n",
        "Y_pred = decision_tree.predict(test)\n",
        "acc_decision_tree = round(decision_tree.score(train, train_labels) * 100, 2)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzg3i7wi6hpb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm_dt = confusion_matrix(test_labels, Y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_dt = classification_report(test_labels, Y_pred)\n",
        "print(report_dt)\n",
        "cm_dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr2ntizYonG_"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(train, train_labels)\n",
        "Y_pred = random_forest.predict(test)\n",
        "random_forest.score(train, train_labels)\n",
        "acc_random_forest = round(random_forest.score(train, train_labels) * 100, 2)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol6okhIN66W6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm_rf = confusion_matrix(test_labels, Y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_rf = classification_report(test_labels, Y_pred)\n",
        "print(report_rf)\n",
        "cm_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD-7iVDLy6qE"
      },
      "outputs": [],
      "source": [
        "# Gaussian Naive Bayes\n",
        "\n",
        "gaussian = GaussianNB()\n",
        "gaussian.fit(train, train_labels)\n",
        "Y_pred = gaussian.predict(test)\n",
        "acc_gaussian = round(gaussian.score(train, train_labels) * 100, 2)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Eizfqol7sAE"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm_nb = confusion_matrix(test_labels, Y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_nb = classification_report(test_labels, Y_pred)\n",
        "print(report_nb)\n",
        "cm_nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-QMNrvnonHA"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['KNN','Random Forest','Decision Tree','Naive Bayes'],\n",
        "    'Score': [acc_knn,acc_random_forest, acc_decision_tree,acc_gaussian]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_x6ROyJKbv3"
      },
      "source": [
        "# PCA Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU0QxtE9D80r"
      },
      "outputs": [],
      "source": [
        "\n",
        "features = pca_features[:, :2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nNiZFvPMojo"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioC5_cwxMMEJ"
      },
      "outputs": [],
      "source": [
        "#Use rating as label\n",
        "labels = pca_features[:, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFfrseKDMqTG"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlZJ4cVWW2_1"
      },
      "outputs": [],
      "source": [
        "ilabels = np.round(labels).astype(int)\n",
        "ilabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjlFe0UEXEud"
      },
      "outputs": [],
      "source": [
        "ipca_features = np.round(features).astype(int)\n",
        "ipca_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RvJzoUUbtCs"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Print the shape of your input data and labels\n",
        "print('Input data shape:', pca_features.shape)\n",
        "print('Labels shape:', labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUMeN4gFdmWO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "# Discretize the label data into 5 bins\n",
        "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
        "labels_discrete = discretizer.fit_transform(labels.reshape(-1, 1)).flatten()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycv1Dadrd07n"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVW2W5sfUs92"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_features, labels_discrete, test_size=0.33, random_state=42)\n",
        "\n",
        "# Create a pipeline with data scaling, PCA, and decision tree classifier\n",
        "pca_dt = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=3)),\n",
        "    ('dt', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pca_dt.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "pdt_accuracy = pca_dt.score(X_test, y_test)\n",
        "print('Accuracy:', pdt_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvp_ppACigdD"
      },
      "outputs": [],
      "source": [
        "# Generate the predicted labels\n",
        "y_pred = pca_dt.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "pdt = confusion_matrix(y_test, y_pred)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssYpivZuglQx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "# Generate the confusion matrix\n",
        "pdt = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_pcadt = classification_report(y_test, y_pred)\n",
        "print(report_pcadt)\n",
        "pdt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUMG77wLd6sU"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uCr2QGdeAJP"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_features, labels_discrete, test_size=0.33, random_state=42)\n",
        "\n",
        "# Create a pipeline with data scaling, PCA, and random forest classifier\n",
        "pca_rf = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=3)),\n",
        "    ('rf', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pca_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "prf_accuracy = pca_rf.score(X_test, y_test)\n",
        "print('Accuracy:', prf_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIBePEOUiyaX"
      },
      "outputs": [],
      "source": [
        "# Generate the predicted labels\n",
        "y_pred = pca_rf.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "prf = confusion_matrix(y_test, y_pred)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt-uIG3fi2e3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "# Generate the confusion matrix\n",
        "prf = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_prf = classification_report(y_test, y_pred)\n",
        "print(report_prf)\n",
        "prf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-mEfR6qeKRx"
      },
      "source": [
        "# SVD Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqOm-YLDeRDT"
      },
      "outputs": [],
      "source": [
        "features = svd_features[:, :2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq3ObyUOe0SQ"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQSugiBEeYxe"
      },
      "outputs": [],
      "source": [
        "labels = svd_features[:, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZjzllZJe1aq"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko6bH3VNe57C"
      },
      "outputs": [],
      "source": [
        "ilabels = np.round(labels).astype(int)\n",
        "ilabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xuxJ3_7e9bv"
      },
      "outputs": [],
      "source": [
        "ipca_features = np.round(features).astype(int)\n",
        "ipca_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntKWC6scfFVY"
      },
      "outputs": [],
      "source": [
        "# Print the shape of your input data and labels\n",
        "print('Input data shape:', pca_features.shape)\n",
        "print('Labels shape:', labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQLKmNCzfJvx"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "# Discretize the label data into 5 bins\n",
        "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
        "labels_discrete = discretizer.fit_transform(labels.reshape(-1, 1)).flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-mDtuzfTDl"
      },
      "source": [
        "## DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF0OIothfQUA"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(svd_features, labels_discrete, test_size=0.33, random_state=42)\n",
        "\n",
        "# Create a pipeline with data scaling, TruncatedSVD, and decision tree classifier\n",
        "svd_dt = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svd', TruncatedSVD(n_components=1)),\n",
        "    ('dt', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "svd_dt.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "sdt_accuracy = svd_dt.score(X_test, y_test)\n",
        "print('Accuracy:', sdt_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGU_TiPdjXlV"
      },
      "outputs": [],
      "source": [
        "# Generate the predicted labels\n",
        "y_pred = svd_dt.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "sdt = confusion_matrix(y_test, y_pred)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7-9scddkTqK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "# Generate the confusion matrix\n",
        "sdt = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_sdt = classification_report(y_test, y_pred)\n",
        "print(report_sdt)\n",
        "sdt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWLHQ8FefiMl"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBjLqni0fWZL"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(svd_features, labels_discrete, test_size=0.33, random_state=42)\n",
        "\n",
        "# Create a pipeline with data scaling, TruncatedSVD, and decision tree classifier\n",
        "svd_rf = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svd', TruncatedSVD(n_components=1)),\n",
        "    ('rf', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "svd_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "srf_accuracy = svd_rf.score(X_test, y_test)\n",
        "print('Accuracy:', srf_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoOh-V70l_aO"
      },
      "outputs": [],
      "source": [
        "# Generate the predicted labels\n",
        "y_pred = svd_rf.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "srf = confusion_matrix(y_test, y_pred)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16veBD0dmFYu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
        "\n",
        "# Generate the confusion matrix\n",
        "srf = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report_srf = classification_report(y_test, y_pred)\n",
        "print(report_srf)\n",
        "srf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpkg38l5q0jx"
      },
      "source": [
        "# result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_lfh5OAq2md"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['PCA Random Forest','PCA Decision Tree','SVD Random Forest','SVD Decision Tree'],\n",
        "    'Score': [prf_accuracy*100,pdt_accuracy*100, srf_accuracy*100,sdt_accuracy*100]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzAyfuu0z3lL"
      },
      "outputs": [],
      "source": [
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EuBCQcoaDgV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df_ratings = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/ratings.dat', sep='::', names=['user_id', 'movie_id', 'rating', 'timestamp'], engine='python')\n",
        "df_movies = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/movies.dat', sep='::', names=['movie_id', 'title', 'genres'], engine='python', encoding='ISO-8859-1')\n",
        "df_users = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/users.dat', sep='::', names=['user_id', 'gender', 'age', 'occupation', 'zip_code'], engine='python')\n",
        "\n",
        "# Convert the data into the format required by Surprise\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df_ratings[['user_id', 'movie_id', 'rating']], reader)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use the SVD algorithm for collaborative filtering\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the training set\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Get predictions for the test set\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Print the RMSE score of the model\n",
        "from surprise import accuracy\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print('RMSE:', rmse)\n",
        "\n",
        "# Generate recommendations for a specific user\n",
        "user_id = 1\n",
        "user_movies = df_ratings[df_ratings['user_id'] == user_id]['movie_id']\n",
        "user_unseen_movies = df_movies[~df_movies['movie_id'].isin(user_movies)]['movie_id']\n",
        "user_unseen_movies = list(user_unseen_movies.values)\n",
        "user_ratings = []\n",
        "for movie_id in user_unseen_movies:\n",
        "    user_ratings.append((user_id, movie_id, 4))  # assume a rating of 4 for all unseen movies\n",
        "user_predictions = algo.test(user_ratings)\n",
        "user_predictions = sorted(user_predictions, key=lambda x: x.est, reverse=True)\n",
        "\n",
        "# Print the top 10 recommended movies for the user\n",
        "print(f\"Top 10 recommended movies for user {user_id}:\")\n",
        "for i, prediction in enumerate(user_predictions[:10]):\n",
        "    movie_id = prediction.iid\n",
        "    movie_title = df_movies[df_movies['movie_id'] == movie_id]['title'].values[0]\n",
        "    print(f\"{i+1}. {movie_title} ({prediction.est:.2f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3VHAW8Caskk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load a random subset of the ratings dataset\n",
        "ratings = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/ratings.dat', sep='::', names=['user_id', 'movie_id', 'rating', 'timestamp'], engine='python')\n",
        "ratings = ratings.sample(n=100000, random_state=42)\n",
        "\n",
        "# Load the movies dataset\n",
        "movies = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/movies.dat', sep='::', names=['movie_id', 'title', 'genres'], engine='python', encoding='ISO-8859-1')\n",
        "# Merge the movies and ratings datasets\n",
        "df = pd.merge(movies, ratings, on='movie_id')\n",
        "\n",
        "# Convert the dataset into a transaction format\n",
        "transactions = df.groupby(['user_id', 'title'])['rating'].max().unstack().reset_index().fillna(0).set_index('user_id')\n",
        "\n",
        "# Encode the transaction data into a binary matrix\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit_transform(transactions.values)\n",
        "basket_sets = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Perform association mining using the Apriori algorithm\n",
        "frequent_itemsets = apriori(basket_sets, min_support=0.1, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "\n",
        "# Display the association rules\n",
        "print(rules)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "df_movies = pd.read_csv('https://raw.githubusercontent.com/droideronline/Business-Analytics-Movielens-Analysis/main/movies.dat', sep='::', names=['movie_id', 'title', 'genres'], engine='python', encoding='ISO-8859-1')\n",
        "\n",
        "# Create a genre matrix\n",
        "tfidf = TfidfVectorizer()\n",
        "genre_matrix = tfidf.fit_transform(df_movies['genres'])\n",
        "\n",
        "# Compute cosine similarity between all movie pairs\n",
        "cosine_sim = cosine_similarity(genre_matrix, genre_matrix)\n",
        "\n",
        "# Define function to get top n similar movies\n",
        "def get_similar_movies(movie_id, n=10):\n",
        "    # Get the row index of the given movie\n",
        "    idx = df_movies[df_movies['movie_id'] == movie_id].index[0]\n",
        "    # Get the pairwise similarity scores of this movie with all others\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    # Sort the movies based on their similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    # Get the movie indices of the top n similar movies\n",
        "    movie_indices = [i[0] for i in sim_scores[1:n+1]]\n",
        "    # Return the titles of the top n similar movies\n",
        "    return df_movies['title'].iloc[movie_indices]\n",
        "\n",
        "# Example usage: get top 10 movies similar to Toy Story (1995)\n",
        "get_similar_movies(1, 10)\n"
      ],
      "metadata": {
        "id": "I7h6XIUL8aIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}